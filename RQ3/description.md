We want to explore the rate at which AI agents produce code contributions. It would be interesting to examine just how efficient at producing correct and reliable code these agents are, and the overall time it takes for an agent to complete its task and for its PR to be approved.  
  
**Methodologies:**  
  Several techniques will be used to examine the efficiency of AI agents. Some of these will include comparing the ‘issue’ tables created_at date to its linked PR’s created_at, closed_at and merged_at dates. From these timestamp values we can determine the amount of time it takes for the agent to create, fix and finish the coding tasks. We can obtain averages for all such comparison values in the dataset to estimate the efficiency of Ai agents at completing tasks. To go in more detail and if time permits, we may consider including the values for ‘additions’, ‘deletions’ and ‘changes’ in the pr_commit_details table within these measurements, to get an estimate of how many lines of code or how many ‘changes’ the agents can make in a certain amount of time. Pie charts and graphs will be constructed in python to help visualize and compare these various metrics and form our conclusions.
